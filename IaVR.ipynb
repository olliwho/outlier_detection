{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IaVR.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1SqDPpkjJZJvf1Yz5VgVUAh-FMpnxPzrT",
      "authorship_tag": "ABX9TyNElkQHw+gqrJzX+UbT4/ev"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V6h9KoUvNhU"
      },
      "source": [
        "Code to install additional alibi_detect library in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXugxSopTWm"
      },
      "source": [
        "!pip install alibi_detect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2AYcnewQUs"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFAtEGwxwO4p"
      },
      "source": [
        "from alibi_detect.models import PixelCNN\n",
        "from alibi_detect.models.losses import elbo\n",
        "from alibi_detect.models.autoencoder import eucl_cosim_features\n",
        "from alibi_detect.od import OutlierVAE, OutlierVAEGMM, LLR\n",
        "from alibi_detect.utils.saving import save_detector, load_detector\n",
        "from alibi_detect.utils.fetching import fetch_detector\n",
        "from alibi_detect.utils import visualize as viz\n",
        "from alibi_detect.utils.perturbation import apply_mask\n",
        "from alibi_detect.utils.prediction import predict_batch\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.metrics import MeanSquaredError, AUC, Precision, Recall\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9HfsPVYvrKa"
      },
      "source": [
        "Check if GPU acceleration is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9tqfzgAtJcC"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY7k3GUoVvBR"
      },
      "source": [
        "Upload and unzip pretrained model files zip in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8LsGh78cucD"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EN4_9mvEwdo"
      },
      "source": [
        "!unzip \"detectors(3).zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9x_sYh7wfA1"
      },
      "source": [
        "Mount Drive to load models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imOLkpcgwOhK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/detectors\"\n",
        "plots_path = \"/content/drive/MyDrive/plots\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1R_zxd9Vhqo"
      },
      "source": [
        "Create folders for output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpA4wZOTopy4"
      },
      "source": [
        "try:\n",
        "    os.mkdir(\"/content/detectors\")\n",
        "except FileExistsError as e:\n",
        "    print(\"Directory exists already!\")\n",
        "try:\n",
        "    os.mkdir(\"/content/plots\")\n",
        "except FileExistsError as e:\n",
        "    print(\"Directory exists already!\")\n",
        "path = \"/content/drive/MyDrive/detectors\"\n",
        "plots_path = \"/content/plots\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09E-4N1xCGow"
      },
      "source": [
        "# Cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpY5OGJH__6e"
      },
      "source": [
        "### Load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E61Hu7cy_8ZR"
      },
      "source": [
        "dataset = 'cifar10'\n",
        "train, test = tf.keras.datasets.cifar10.load_data()\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "\n",
        "# X_train = X_train[:15000]\n",
        "# y_train = y_train[:15000]\n",
        "\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "X = X_train[:500]\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(X.shape)\n",
        "\n",
        "input_shape=X_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW_VU556g3zj"
      },
      "source": [
        "# randoms = [[random.randint(0, len(X_train)-1)] for _ in range(64)]\n",
        "# plt.figure(figsize=(8,8), frameon=False)\n",
        "# for i, idx in enumerate(randoms):\n",
        "#     plt.subplot(8,8,i+1)\n",
        "#     x = X_train[idx].reshape(1, 32, 32, 3)\n",
        "#     plt.imshow(x.reshape(32, 32, 3))\n",
        "#     plt.axis('off')\n",
        "# plt.subplots_adjust(wspace=0,hspace=0)\n",
        "# plt.savefig(os.path.join(plots_path, \"cifar10\"))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1klx_z7EwY8o"
      },
      "source": [
        "## VAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuF8ZRs_ztBO"
      },
      "source": [
        "fetch = False\n",
        "load = True\n",
        "epochs = 50\n",
        "th = 0.1\n",
        "s = 2\n",
        "ld = 1024\n",
        "bs = 56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgBV99Zt8IPV"
      },
      "source": [
        "if fetch:\n",
        "    detector_type = 'outlier'\n",
        "    detector_name = 'OutlierVAE'\n",
        "    dataset = 'cifar10'\n",
        "    od_v = fetch_detector(path, detector_type, dataset, detector_name)\n",
        "elif load:\n",
        "    od_v = load_detector(os.path.join(path, 'OutlierVAE_Cifar10'))\n",
        "else:\n",
        "    encoder = tf.keras.Sequential([InputLayer(input_shape=input_shape),\n",
        "                            Conv2D(32, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
        "                            ])\n",
        "    \n",
        "    decoder = tf.keras.Sequential([InputLayer(input_shape=(ld,)),\n",
        "                            Dense(4*4*128),\n",
        "                            Reshape(target_shape=(4, 4, 128)),\n",
        "                            Conv2DTranspose(256, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(32, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
        "                            ])\n",
        "\n",
        "    od_v = OutlierVAE(threshold=None, \n",
        "                        score_type='mse', \n",
        "                        encoder_net=encoder,\n",
        "                        decoder_net=decoder, \n",
        "                        latent_dim=ld, \n",
        "                        samples=s)\n",
        "\n",
        "\n",
        "    od_v.fit(X_train, \n",
        "                loss_fn=elbo,\n",
        "                cov_elbo=dict(sim=.05), \n",
        "                epochs=epochs, \n",
        "                batch_size=bs,\n",
        "                verbose=True)\n",
        "\n",
        "    od_v.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers\n",
        "    print('New threshold: {}'.format(od_v.threshold))\n",
        "\n",
        "    save_detector(od_v, os.path.join(path, 'OutlierVAE_Cifar10'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9y5If_f1teh"
      },
      "source": [
        "## VAEGMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Uui7gUK3bM"
      },
      "source": [
        "load = True\n",
        "epochs = 50\n",
        "th = 0.1\n",
        "s = 2 \n",
        "ld = 4\n",
        "n_gmm = 2\n",
        "bs = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjR77rpKR4e9"
      },
      "source": [
        "if load:\n",
        "    od_vg = load_detector(os.path.join(path, 'OutlierVAEGMM_Cifar10'))\n",
        "else:\n",
        "    encoder = tf.keras.Sequential([InputLayer(input_shape=input_shape),\n",
        "                            Conv2D(5, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(10, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(20, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
        "                            ])\n",
        "    \n",
        "    decoder = tf.keras.Sequential([InputLayer(input_shape=(ld,)),\n",
        "                            Dense(4*4*128),\n",
        "                            Reshape(target_shape=(4, 4, 128)),\n",
        "                            Conv2DTranspose(20, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(10, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
        "                            ])\n",
        "\n",
        "    gmm_density = tf.keras.Sequential([InputLayer(input_shape=(ld + 2,)),\n",
        "                                Dense(10, activation=tf.nn.relu),\n",
        "                                Dense(n_gmm, activation=tf.nn.softmax)\n",
        "                                ])\n",
        "\n",
        "    od_vg = OutlierVAEGMM(threshold=None, \n",
        "                            encoder_net=encoder, \n",
        "                            decoder_net=decoder, \n",
        "                            gmm_density_net=gmm_density, \n",
        "                            latent_dim=ld, \n",
        "                            n_gmm=n_gmm, \n",
        "                            samples=s, \n",
        "                            recon_features=eucl_cosim_features)\n",
        "\n",
        "\n",
        "    losses = od_vg.fit(X_train, \n",
        "                        cov_elbo=dict(sim=.05),\n",
        "                        epochs=epochs, \n",
        "                        batch_size=bs, \n",
        "                        verbose=True)\n",
        "    \n",
        "    print(losses)\n",
        "\n",
        "    od_vg.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers\n",
        "    print('New threshold: {}'.format(od_vg.threshold))\n",
        "\n",
        "    save_detector(od_vg, os.path.join(path, 'OutlierVAEGMM_Cifar10'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJotAkewWL8e"
      },
      "source": [
        "## LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHwHhllBWZQw"
      },
      "source": [
        "load = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R53BS1SqWcG8"
      },
      "source": [
        "model = PixelCNN(\n",
        "    image_shape=input_shape,\n",
        "    num_resnet=5,\n",
        "    num_hierarchies=2,\n",
        "    num_filters=32,\n",
        "    num_logistic_mix=1,\n",
        "    receptive_field_dims=(3, 3),\n",
        "    dropout_p=.3,\n",
        "    l2_weight=0.\n",
        ")\n",
        "\n",
        "if load:\n",
        "    kwargs = {'dist_s': model, 'dist_b': model.copy(), 'input_shape': input_shape}\n",
        "    od_lr = load_detector(os.path.join(path, \"LR_Cifar10\"), **kwargs)\n",
        "else:\n",
        "    od_lr = LLR(threshold=None, model=model)\n",
        "    od_lr.fit(\n",
        "            X_train,\n",
        "            mutate_fn_kwargs=dict(rate=.2),\n",
        "            mutate_batch_size=1000,\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "            epochs=20,\n",
        "            batch_size=32,\n",
        "            verbose=True\n",
        "        )\n",
        "    \n",
        "    od_lr.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers\n",
        "    print('New threshold: {}'.format(od_lr.threshold))\n",
        "\n",
        "    save_detector(od_lr, os.path.join(path, 'LR_Cifar10'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwP8adH-zX5"
      },
      "source": [
        "# MNIST/Fashion-MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNqJMQ6zVJiG"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDS3_X-FcICF"
      },
      "source": [
        "def load_data(dataset: str) -> tuple:\n",
        "    if dataset == 'mnist':\n",
        "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    elif dataset == 'fashion_mnist':\n",
        "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    X_train = X_train.astype('float32') / 255\n",
        "    X_test = X_test.astype('float32') / 255\n",
        "    y_train = y_train.astype('int64').reshape(-1,)\n",
        "    y_test = y_test.astype('int64').reshape(-1,)\n",
        "    if len(X_train.shape) == 3:\n",
        "        shape = (-1,) + X_train.shape[1:] + (1,)\n",
        "        X_train = X_train.reshape(shape)\n",
        "        X_test = X_test.reshape(shape)\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "(X_train_in, y_train_in), (X_test_in, y_test_in) = load_data('fashion_mnist')\n",
        "\n",
        "X_train_in = np.pad(X_train_in,((0,0),(2,2),(2,2),(0,0)),constant_values=(0,))\n",
        "X_test_in = np.pad(X_test_in,((0,0),(2,2),(2,2),(0,0)),constant_values=(0,))\n",
        "\n",
        "\n",
        "X_test_ood, y_test_ood = load_data('mnist')[1]\n",
        "\n",
        "X_test_ood = np.pad(X_test_ood, ((0,0),(2,2),(2,2),(0,0)), constant_values=(0,))\n",
        "\n",
        "\n",
        "input_shape = X_train_in.shape[1:]\n",
        "\n",
        "print(X_train_in.shape, X_test_in.shape, X_test_ood.shape)\n",
        "print(y_train_in.shape, y_test_in.shape, y_test_ood.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQOM1AK5Wf0K"
      },
      "source": [
        "randoms = [[random.randint(0, len(X_train_in)-1)] for _ in range(64)]\n",
        "plt.figure(figsize=(8,8), frameon=False)\n",
        "for i, idx in enumerate(randoms):\n",
        "    plt.subplot(8,8,i+1)\n",
        "    x = X_train_in[idx].reshape(1, 32, 32, 1)\n",
        "    plt.imshow(x.reshape(32, 32))\n",
        "    plt.axis('off')\n",
        "plt.subplots_adjust(wspace=0,hspace=0)\n",
        "plt.savefig(os.path.join(plots_path, \"f_mnist\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4jZvmnFZqh0"
      },
      "source": [
        "randoms = [[random.randint(0, len(X_test_ood)-1)] for _ in range(64)]\n",
        "plt.figure(figsize=(8,8), frameon=False)\n",
        "for i, idx in enumerate(randoms):\n",
        "    plt.subplot(8,8,i+1)\n",
        "    x = X_test_ood[idx].reshape(1, 32, 32, 1)\n",
        "    plt.imshow(x.reshape(32, 32))\n",
        "    plt.axis('off')\n",
        "plt.subplots_adjust(wspace=0,hspace=0)\n",
        "plt.savefig(os.path.join(plots_path, \"mnist\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4tkWsIIU4Vx"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouuPlApEGVS5"
      },
      "source": [
        "load = False\n",
        "epochs = 50\n",
        "th = 0.1\n",
        "s = 2\n",
        "ld = 1024\n",
        "bs = 56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l6yPJFlGXFR"
      },
      "source": [
        "if load:\n",
        "    od_v1 = load_detector(os.path.join(path, 'OutlierVAE_FMNIST'))\n",
        "else:\n",
        "    encoder = tf.keras.Sequential([InputLayer(input_shape=input_shape),\n",
        "                            Conv2D(32, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
        "                            ])\n",
        "    \n",
        "    decoder = tf.keras.Sequential([InputLayer(input_shape=(ld,)),\n",
        "                            Dense(4*4*128),\n",
        "                            Reshape(target_shape=(4, 4, 128)),\n",
        "                            Conv2DTranspose(256, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(32, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(1, 4, strides=2, padding='same', activation='sigmoid')\n",
        "                            ])\n",
        "\n",
        "\n",
        "    od_v1 = OutlierVAE(threshold=None, \n",
        "                        score_type='mse', \n",
        "                        encoder_net=encoder,\n",
        "                        decoder_net=decoder, \n",
        "                        latent_dim=ld, \n",
        "                        samples=s)\n",
        "\n",
        "    od_v1.fit(X_train_in, \n",
        "                loss_fn=elbo,\n",
        "                cov_elbo=dict(sim=.05), \n",
        "                epochs=epochs, \n",
        "                batch_size=bs,\n",
        "                verbose=True)\n",
        "\n",
        "    save_detector(od_v1, os.path.join(path, 'OutlierVAE_FMNIST'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpoqHAkQU8k2"
      },
      "source": [
        "## VAEGMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhT37wn1_o_l"
      },
      "source": [
        "load = False\n",
        "epochs = 50\n",
        "th = 0.1\n",
        "s = 2 \n",
        "ld = 4\n",
        "n_gmm = 2\n",
        "bs = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jubm_8qR_lYI"
      },
      "source": [
        "if load:\n",
        "    od_vg1 = load_detector(os.path.join(path, 'OutlierVAEGMM_FMNIST'))\n",
        "else:\n",
        "    encoder = tf.keras.Sequential([InputLayer(input_shape=input_shape),\n",
        "                            Conv2D(5, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(10, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2D(20, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
        "                            ])\n",
        "    \n",
        "    decoder = tf.keras.Sequential([InputLayer(input_shape=(ld,)),\n",
        "                            Dense(4*4*128),\n",
        "                            Reshape(target_shape=(4, 4, 128)),\n",
        "                            Conv2DTranspose(20, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(10, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "                            Conv2DTranspose(1, 4, strides=2, padding='same', activation='sigmoid')\n",
        "                            ])\n",
        "\n",
        "    gmm_density = tf.keras.Sequential([InputLayer(input_shape=(ld + 2,)),\n",
        "                                Dense(10, activation=tf.nn.relu),\n",
        "                                Dense(n_gmm, activation=tf.nn.softmax)\n",
        "                                ])\n",
        "\n",
        "    od_vg1 = OutlierVAEGMM(threshold=None, \n",
        "                            encoder_net=encoder, \n",
        "                            decoder_net=decoder, \n",
        "                            gmm_density_net=gmm_density, \n",
        "                            latent_dim=ld, \n",
        "                            n_gmm=n_gmm, \n",
        "                            samples=s, \n",
        "                            recon_features=eucl_cosim_features)\n",
        "\n",
        "\n",
        "    od_vg1.fit(X_train_in, \n",
        "                cov_elbo=dict(sim=.05),\n",
        "                epochs=epochs, \n",
        "                batch_size=bs, \n",
        "                verbose=True)\n",
        "\n",
        "    save_detector(od_vg1, os.path.join(path, 'OutlierVAEGMM_FMNIST'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHrtW5ztSBRc"
      },
      "source": [
        "## LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb2NE2_5dKTs"
      },
      "source": [
        "fetch = False\n",
        "load = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obClXysu2DOw"
      },
      "source": [
        "model = PixelCNN(\n",
        "    image_shape=input_shape,\n",
        "    num_resnet=5,\n",
        "    num_hierarchies=2,\n",
        "    num_filters=32,\n",
        "    num_logistic_mix=1,\n",
        "    receptive_field_dims=(3, 3),\n",
        "    dropout_p=.3,\n",
        "    l2_weight=0.\n",
        ")\n",
        "\n",
        "if fetch:\n",
        "    detector_type = 'outlier'\n",
        "    dataset = 'fashion_mnist'\n",
        "    detector_name = 'LLR'\n",
        "    od_lr1 = fetch_detector(path, detector_type, dataset, detector_name)\n",
        "elif load:\n",
        "    kwargs = {'dist_s': model, 'dist_b': model.copy(), 'input_shape': input_shape}\n",
        "    od_lr1 = load_detector(os.path.join(path, \"LR_FMNIST\"), **kwargs)\n",
        "else:\n",
        "    od_lr1 = LLR(threshold=None, model=model)\n",
        "    od_lr1.fit(\n",
        "            X_train_in,\n",
        "            mutate_fn_kwargs=dict(rate=.2),\n",
        "            mutate_batch_size=1000,\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "            epochs=20,\n",
        "            batch_size=32,\n",
        "            verbose=True\n",
        "        )\n",
        "    save_detector(od_lr1, os.path.join(path, 'LR_FMNIST'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO70Tp0MKHSG"
      },
      "source": [
        "## Infer thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCQiCoX1aoJd"
      },
      "source": [
        "shape_in, shape_ood = X_test_in.shape[0], X_test_ood.shape[0]\n",
        "\n",
        "n, frac_outlier = 500, .5\n",
        "perc_outlier = 100 * frac_outlier\n",
        "n_in, n_ood = int(n * (1 - frac_outlier)), int(n * frac_outlier)\n",
        "idx_in = np.random.choice(shape_in, size=n_in, replace=False)\n",
        "idx_ood = np.random.choice(shape_ood, size=n_ood, replace=False)\n",
        "X_threshold = np.concatenate([X_test_in[idx_in], X_test_ood[idx_ood]])\n",
        "\n",
        "# od_v.infer_threshold(X_threshold, threshold_perc=perc_outlier, batch_size=56)\n",
        "# od_vg.infer_threshold(X_threshold, threshold_perc=perc_outlier, batch_size=56)\n",
        "od_lr1.infer_threshold(X_threshold, threshold_perc=perc_outlier, batch_size=32)\n",
        "print(od_lr1.threshold)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE3TWMXJ8Cyb"
      },
      "source": [
        "# Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHGjzO3PTOt0"
      },
      "source": [
        "## Cifar 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZD2UGirqQ-Z"
      },
      "source": [
        "Set thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h042kEjqqNxf"
      },
      "source": [
        "od_v.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers\n",
        "od_vg.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers\n",
        "od_lr.infer_threshold(X, threshold_perc=99)  # assume 1% of the training data are outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7GG4JRhzao7"
      },
      "source": [
        "#VAE\n",
        "od_v_preds = od_v.predict(X)\n",
        "\n",
        "#VAEGMM\n",
        "od_vg_preds = od_vg.predict(X)\n",
        "\n",
        "#LR\n",
        "od_lr_preds = od_lr.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDrfyZJdWG9p"
      },
      "source": [
        "from typing import Dict, Union\n",
        "def plot_instance_score(preds: Dict,\n",
        "                        target: np.ndarray,\n",
        "                        labels: np.ndarray,\n",
        "                        threshold: float,\n",
        "                        ylim: tuple = (None, None)) -> None:\n",
        "\n",
        "    scores = preds['data']['instance_score']\n",
        "    df = pd.DataFrame(dict(idx=np.arange(len(scores)), score=scores, label=target))\n",
        "    groups = df.groupby('label')\n",
        "    fig, ax = plt.subplots()\n",
        "    for name, group in groups:\n",
        "        ax.plot(group.idx, group.score, marker='o', linestyle='', ms=6, label=labels[name])\n",
        "    plt.plot(np.arange(len(scores)), np.ones(len(scores)) * threshold, color='g', label='Threshold')\n",
        "    plt.ylim(ylim)\n",
        "    plt.xlabel('Number of Instances')\n",
        "    plt.ylabel('Instance Level Score')\n",
        "    ax.legend()\n",
        "\n",
        "# target = np.zeros(X.shape[0],).astype(int)  # all normal CIFAR10 training instances\n",
        "# target = y_test.reshape([500])\n",
        "# target = outlier_batch_target.reshape(outlier_batch_target.shape[0])\n",
        "plt.figure()\n",
        "labels = ['normal', 'outlier']\n",
        "\n",
        "#VAE\n",
        "target = od_v_preds['data']['is_outlier']\n",
        "plot_instance_score(od_v_preds, target, labels, od_v.threshold)\n",
        "plt.savefig(os.path.join(plots_path, \"instance_score_vae.png\"))\n",
        "# plt.show()\n",
        "\n",
        "#VAEGMM\n",
        "target = od_vg_preds['data']['is_outlier']\n",
        "plot_instance_score(od_vg_preds, target, labels, od_vg.threshold)\n",
        "plt.savefig(os.path.join(plots_path, \"instance_score_vaegmm.png\"))\n",
        "# plt.show()\n",
        "\n",
        "#LR\n",
        "target = od_lr_preds['data']['is_outlier']\n",
        "plot_instance_score(od_lr_preds, target, labels, od_lr.threshold)\n",
        "plt.savefig(os.path.join(plots_path, \"instance_score_lr.png\"))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwvfvEYf_9z"
      },
      "source": [
        "n_mask_sizes = 10\n",
        "n_masks = 20\n",
        "n_imgs = 50\n",
        "\n",
        "mask_sizes = [(2*n,2*n) for n in range(1,n_mask_sizes+1)]\n",
        "print(mask_sizes)\n",
        "img_ids = np.arange(n_imgs)\n",
        "X_orig = X[img_ids].reshape(img_ids.shape[0], 32, 32, 3)\n",
        "print(X_orig.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZLK4M5Xhf16"
      },
      "source": [
        "all_img_scores_v = []\n",
        "all_img_scores_vg = []\n",
        "all_img_scores_lr = []\n",
        "for i in tqdm(range(X_orig.shape[0])):\n",
        "    img_scores_v = np.zeros((len(mask_sizes),))\n",
        "    img_scores_vg = np.zeros((len(mask_sizes),))\n",
        "    img_scores_lr = np.zeros((len(mask_sizes),))\n",
        "    for j, mask_size in enumerate(mask_sizes):\n",
        "        # create masked instances\n",
        "        X_mask, mask = apply_mask(X_orig[i].reshape(1, 32, 32, 3),\n",
        "                                  mask_size=mask_size,\n",
        "                                  n_masks=n_masks,\n",
        "                                  channels=[0,1,2],\n",
        "                                  mask_type='normal',\n",
        "                                  noise_distr=(0,1),\n",
        "                                  clip_rng=(0,1))\n",
        "        # predict outliers\n",
        "        od_v_preds_mask = od_v.predict(X_mask)\n",
        "        od_vg_preds_mask = od_vg.predict(X_mask)\n",
        "        od_lr_preds_mask = od_lr.predict(X_mask)\n",
        "\n",
        "        score_v = od_v_preds_mask['data']['instance_score']\n",
        "        score_vg = od_vg_preds_mask['data']['instance_score']\n",
        "        score_lr = od_lr_preds_mask['data']['instance_score']\n",
        "\n",
        "        # store average score over `n_masks` for a given mask size\n",
        "        img_scores_v[j] = np.mean(score_v)\n",
        "        img_scores_vg[j] = np.mean(score_vg)\n",
        "        img_scores_lr[j] = np.mean(score_lr)\n",
        "\n",
        "    all_img_scores_v.append(img_scores_v)\n",
        "    all_img_scores_vg.append(img_scores_vg)\n",
        "    all_img_scores_lr.append(img_scores_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dev706ICzVoo"
      },
      "source": [
        "x = X_train[34].reshape(1, 32, 32, 3)\n",
        "x_mask, mask = apply_mask(x, mask_size=(12, 12), n_masks=1, channels=[0,1,2], \n",
        "                          mask_type='normal', noise_distr=(0,1), clip_rng=(0,1))\n",
        "plt.imshow(x.reshape(32, 32, 3))\n",
        "plt.axis('off')\n",
        "plt.savefig(os.path.join(plots_path, \"normal.png\"))\n",
        "plt.show()\n",
        "plt.imshow(x_mask.reshape(32, 32, 3))\n",
        "plt.axis('off')\n",
        "plt.savefig(os.path.join(plots_path, \"preturbed.png\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t95vZRgYiLi5"
      },
      "source": [
        "x_plt = [mask[0] for mask in mask_sizes]\n",
        "for ais in all_img_scores_v:\n",
        "    plt.plot(x_plt, ais)\n",
        "    plt.xticks(x_plt)\n",
        "plt.title('Outlier Score All Images for Increasing Mask Size')\n",
        "plt.xlabel('Mask size')\n",
        "plt.ylabel('Outlier Score')\n",
        "plt.savefig(os.path.join(plots_path, \"os_inc_mask_vae\"))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzvnOj3fkEv-"
      },
      "source": [
        "for ais in all_img_scores_vg:\n",
        "    plt.plot(x_plt, ais)\n",
        "    plt.xticks(x_plt)\n",
        "plt.title('Outlier Score All Images for Increasing Mask Size')\n",
        "plt.xlabel('Mask size')\n",
        "plt.ylabel('Outlier Score')\n",
        "plt.savefig(os.path.join(plots_path, \"os_inc_mask_vaegmm\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46z_FNAnLAc5"
      },
      "source": [
        "for ais in all_img_scores_lr:\n",
        "    plt.plot(x_plt, ais)\n",
        "    plt.xticks(x_plt)\n",
        "plt.title('Outlier Score All Images for Increasing Mask Size')\n",
        "plt.xlabel('Mask size')\n",
        "plt.ylabel('Outlier Score')\n",
        "plt.savefig(os.path.join(plots_path, \"os_inc_mask_lr\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixqCxCA5mepm"
      },
      "source": [
        "all_X_mask = []\n",
        "X_i = X_orig[8].reshape(1, 32, 32, 3)\n",
        "all_X_mask.append(X_i)\n",
        "# apply masks\n",
        "for j, mask_size in enumerate(mask_sizes):\n",
        "    # create masked instances\n",
        "    X_mask, mask = apply_mask(X_i,\n",
        "                              mask_size=mask_size,\n",
        "                              n_masks=1,  # just 1 for visualization purposes\n",
        "                              channels=[0,1,2],\n",
        "                              mask_type='normal',\n",
        "                              noise_distr=(0,1),\n",
        "                              clip_rng=(0,1))\n",
        "    all_X_mask.append(X_mask)\n",
        "all_X_mask = np.concatenate(all_X_mask, axis=0)\n",
        "all_X_recon = od_v.vae(all_X_mask).numpy()\n",
        "od_preds = od_v.predict(all_X_mask)\n",
        "\n",
        "viz.plot_feature_outlier_image(od_v_preds,\n",
        "                           all_X_mask,\n",
        "                           X_recon=all_X_recon,\n",
        "                           max_instances=all_X_mask.shape[0],\n",
        "                           n_channels=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WZrt5L6ERYs"
      },
      "source": [
        "X_recon = od_v.vae(X).numpy()\n",
        "viz.plot_feature_outlier_image(od_v_preds,\n",
        "                           X,\n",
        "                           X_recon=X_recon,\n",
        "                           instance_ids=[8, 15, 24, 39, 49])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkTnJ5kIoJWn"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exea61vpoOM5"
      },
      "source": [
        "X_test = np.concatenate([X_test_in, X_test_ood])\n",
        "y_test = np.concatenate([np.zeros(X_test_in.shape[0]), np.ones(X_test_ood.shape[0])])\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqkIBhf8oUOM"
      },
      "source": [
        "#VAE\n",
        "# od_v1_preds = od_v1.predict(X_test, batch_size=32)\n",
        "\n",
        "# #VAEGMM\n",
        "# od_vg1_preds = od_vg1.predict(X_test, batch_size=32)\n",
        "\n",
        "#LR\n",
        "od_lr1_preds = od_lr1.predict(X_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKdsaJfWp7yX"
      },
      "source": [
        "def metrics(od_preds):\n",
        "    y_pred = od_preds['data']['is_outlier']\n",
        "    labels = ['normal', 'outlier']\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    print('F1 score: {:.3f} -- Accuracy: {:.3f} -- Precision: {:.3f} '\n",
        "        '-- Recall: {:.3f}'.format(f1, acc, prec, rec))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    sns.heatmap(df_cm, annot=True, cbar=True, linewidths=.5)\n",
        "    plt.show()\n",
        "\n",
        "metrics(od_lr1_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8a2xxFfqBIp"
      },
      "source": [
        "def roc(od, od_preds):\n",
        "    logp_s_in = predict_batch(od.dist_s.log_prob, X_test_in, batch_size=32, shape=shape_in)\n",
        "    logp_s_ood = predict_batch(od.dist_s.log_prob, X_test_ood, batch_size=32, shape=shape_ood)\n",
        "    logp_s = np.concatenate([logp_s_in, logp_s_ood])\n",
        "    roc_data = {\n",
        "        'LLR': {'scores': od_preds['data']['instance_score'], 'labels': y_test},\n",
        "        'Likelihood': {'scores': -logp_s, 'labels': y_test}  # negative b/c outlier score\n",
        "    }\n",
        "    viz.plot_roc(roc_data)\n",
        "\n",
        "roc(od_lr1, od_lr1_preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}